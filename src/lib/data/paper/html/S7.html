<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>VII Conclusion ‣ LLM4DS: Evaluating Large Language Models for Data Science Code Generation</title>
<!--Generated by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->

<link rel="stylesheet" href="LaTeXML.css" type="text/css">
<link rel="stylesheet" href="ltx-article.css" type="text/css">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js?config=MML_HTMLorMML"></script>
<link rel="up" href="paper.html" title="LLM4DS: Evaluating Large Language Models for Data Science Code Generation">
<link rel="start" href="paper.html" title="LLM4DS: Evaluating Large Language Models for Data Science Code Generation">
<link rel="prev" href="S6.html" title="VI Discussion ‣ LLM4DS: Evaluating Large Language Models for Data Science Code Generation">
<link rel="next" href="S8.html" title="VIII Future Work ‣ LLM4DS: Evaluating Large Language Models for Data Science Code Generation">
<link rel="section" href="S1.html" title="I Introduction ‣ LLM4DS: Evaluating Large Language Models for Data Science Code Generation">
<link rel="section" href="S2.html" title="II Related Work ‣ LLM4DS: Evaluating Large Language Models for Data Science Code Generation">
<link rel="section" href="S3.html" title="III Controlled Experiment ‣ LLM4DS: Evaluating Large Language Models for Data Science Code Generation">
<link rel="section" href="S4.html" title="IV Experiment Operation ‣ LLM4DS: Evaluating Large Language Models for Data Science Code Generation">
<link rel="section" href="S5.html" title="V Analysis and Interpretation ‣ LLM4DS: Evaluating Large Language Models for Data Science Code Generation">
<link rel="section" href="S6.html" title="VI Discussion ‣ LLM4DS: Evaluating Large Language Models for Data Science Code Generation">
<link rel="section" href="S8.html" title="VIII Future Work ‣ LLM4DS: Evaluating Large Language Models for Data Science Code Generation">
<link rel="bibliography" href="bib.html" title="References ‣ LLM4DS: Evaluating Large Language Models for Data Science Code Generation">
</head>
<body>
<nav class="ltx_page_navbar"><a href="paper.html" title="" class="ltx_ref" rel="start"><span class="ltx_text ltx_ref_title">LLM4DS: Evaluating Large Language Models for Data Science Code Generation</span></a>
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a href="S1.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="S2.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="S3.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Controlled Experiment</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="S4.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experiment Operation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="S5.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Analysis and Interpretation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="S6.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Discussion</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section ltx_ref_self"><span class="ltx_ref ltx_ref_self"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VII </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></span></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="S8.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VIII </span><span class="ltx_text ltx_font_smallcaps">Future Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_bibliography"><a href="bib.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref"><span class="ltx_text ltx_ref_title">References</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<header class="ltx_page_header">
<div class="ltx_align_center">
<a href="paper.html" title="" class="ltx_ref" rel="up"><span class="ltx_text ltx_ref_title">LLM4DS: Evaluating Large Language Models for Data Science Code Generation</span></a><a href="S6.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref" rel="prev"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Discussion</span></span></a><a href="S8.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref" rel="next"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VIII </span><span class="ltx_text ltx_font_smallcaps">Future Work</span></span></a>
</div></header>
<div class="ltx_page_content">
<section class="ltx_section ltx_authors_1line">
<h1 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h1>

<div id="p1" class="ltx_para">
<p class="ltx_p">This study presents a controlled experiment evaluating the effectiveness of four prominent LLM-based AI assistants—Microsoft Copilot (GPT-4 Turbo), ChatGPT (o1-preview), Claude (3.5 Sonnet), and Perplexity Labs (Llama-3.1-70b-instruct)—in data science coding tasks. Effectiveness was measured by each model’s success rate, execution efficiency, visual output quality, and consistency across difficulty levels and task types.</p>
</div>
<div id="p2" class="ltx_para">
<p class="ltx_p">With success rates exceeding 50% for all models, this research provides valuable insights into LLM performance in data science. At the 60% baseline, only ChatGPT and Claude achieved significantly higher success rates, highlighting their reliability in general coding tasks. However, our findings indicate that only ChatGPT consistently maintains performance across different difficulty levels, whereas Claude’s success rate is significantly affected by task difficulty, suggesting its performance may vary with more complex tasks.</p>
</div>
<div id="p3" class="ltx_para">
<p class="ltx_p">No evidence suggests that task type affects LLM success rates, though ChatGPT (o1-preview) significantly outperforms Copilot (GPT-4o) for analytical and algorithm tasks. This nuanced understanding of each model’s strengths enables more strategic LLM selection tailored to specific needs. Additionally, this study underscores the value of rigorous hypothesis testing in AI evaluation, setting a template for assessing models beyond basic accuracy metrics.</p>
</div>
</section>
</div>
<footer class="ltx_page_footer">
<div class="ltx_align_center">
<a href="S6.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref" rel="prev"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Discussion</span></span></a><a href="bib.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref" rel="bibliography"><span class="ltx_text ltx_ref_title">References</span></a><a href="S8.html" title="In LLM4DS: Evaluating Large Language Models for Data Science Code Generation" class="ltx_ref" rel="next"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VIII </span><span class="ltx_text ltx_font_smallcaps">Future Work</span></span></a>
</div>
<div class="ltx_page_logo">Generated  by <a href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>
</body>
</html>
